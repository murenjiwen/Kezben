Automatically generated by Mendeley 1.1.3
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Molina2011,
abstract = {The use of hand gestures offers an alternative to the commonly used human computer interfaces, providing a more intuitive way of navigating among menus and multimedia applications. This paper presents a system for hand gesture recognition devoted to control windows applications. Starting from the images captured by a time-of-flight camera (a camera that produces images with an intensity level inversely proportional to the depth of the objects observed) the system performs hand segmentation as well as a low-level extraction of potentially relevant features which are related to the morphological representation of the hand silhouette. Classification based on these features discriminates between a set of possible static hand postures which results, combined with the estimated motion pattern of the hand, in the recognition of dynamic hand gestures. The whole system works in real-time, allowing practical interaction between user and application.},
author = {Molina, J and Escudero-Vi\~{n}olo, M},
doi = {10.1007/s00138-011-0364-6},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Molina, Escudero-Vi\~{n}olo - 2011 - Real-time user independent hand gesture recognition from time-of-flight camera video using static and dynamic models.pdf:pdf},
journal = {Machine Vision and Applications},
keywords = {Computer vision,Hand gesture cognition,Human–computer interaction},
title = {{Real-time user independent hand gesture recognition from time-of-flight camera video using static and dynamic models}},
url = {http://www.springerlink.com/index/062M51V58073572H.pdf},
year = {2011}
}
@article{Kelly2011,
abstract = {A system for automatically training and spotting signs from continuous sign language sentences is presented. We propose a novel multiple instance learning density matrix algorithm which automatically extracts isolated signs from full sentences using the weak and noisy supervision of text translations. The automatically extracted isolated samples are then utilized to train our spatiotemporal gesture and hand posture classifiers. The experiments were carried out to evaluate the performance of the automatic sign extraction, hand posture classification, and spatiotemporal gesture spotting systems. We then carry out a full evaluation of our overall sign spotting system which was automatically trained on 30 different signs.},
author = {Kelly, Daniel and {Mc Donald}, John and Markham, Charles},
doi = {10.1109/TSMCB.2010.2065802},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly, Mc Donald, Markham - 2011 - Weakly supervised training of a sign language recognition system using multiple instance learning density matrices.pdf:pdf},
issn = {1941-0492},
journal = {IEEE transactions on systems, man, and cybernetics},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Hand,Hand: anatomy \& histology,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Photography,Photography: methods,Reproducibility of Results,Sensitivity and Specificity,Sign Language},
month = apr,
number = {2},
pages = {526--41},
pmid = {20875974},
title = {{Weakly supervised training of a sign language recognition system using multiple instance learning density matrices.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20875974},
volume = {41},
year = {2011}
}
@article{moosmann2006randomized,
abstract = {Some of the most effective recent methods for content-based image classification work by extracting dense or sparse local image descriptors, quantizing them according to a coding rule such as k-means vector quantization, accumulating histograms of the resulting “visual word” codes over the image, and classifying these with a conventional classifier such as an SVM. Large numbers of descriptors and large codebooks are needed for good results and this becomes slow using k-means. We introduce Extremely Randomized Clustering Forests – ensembles of randomly created clustering trees – and show that these provide more accurate results, much faster training and testing and good resistance to background clutter in several state-of-the-art image classification tasks.},
annote = {Presented at Neural Information Processing Systems (NIPS) 2006},
author = {Moosmann, F. and Triggs, W. and Jurie, F.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moosmann, Triggs, Jurie - 2006 - Randomized clustering forests for building fast and discriminative visual vocabularies.pdf:pdf;:C$\backslash$:/Users/walto011/Downloads/NIPS2006\_0741.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
title = {{Randomized clustering forests for building fast and discriminative visual vocabularies}},
url = {http://eprints.pascal-network.org/archive/00002438/},
volume = {19},
year = {2007}
}
@article{Nowozin2011,
author = {Nowozin, S and Rother, C and Bagon, S and Sharp, T},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nowozin et al. - 2011 - Decision Tree Fields.pdf:pdf},
journal = {ai.stanford.edu},
title = {{Decision Tree Fields}},
url = {http://ai.stanford.edu/~bangpeng/document/iccv11\_0981.pdf},
year = {2011}
}
@article{Smisek,
abstract = {We analyze Kinect as a 3D measuring device, experimen- tally investigate depth measurement resolution and error properties and make a quantitative comparison of Kinect accuracy with stereo reconstruction from SLR cameras and a 3D-TOF camera. We propose Kinect geometrical model and its calibration procedure providing an accurate cali- bration of Kinect 3D measurement and Kinect cameras. We demonstrate the functionality of Kinect calibration by in- tegrating it into an SfM pipeline where 3D measurements from a moving Kinect are transformed into a common coor- dinate system by computing relative poses from matches in color camera.},
author = {Smisek, Jan and Jancosek, Michal and Pajdla, Tomas},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smisek, Jancosek, Pajdla - Unknown - 3D with Kinect.pdf:pdf},
journal = {cmp.felk.cvut.cz},
title = {{3D with Kinect}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:3D+with+Kinect\#0},
year = {2011}
}
@article{breiman2001random,
author = {Breiman, L.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Random forests.pdf:pdf},
journal = {Machine learning},
number = {1},
pages = {5--32},
publisher = {Springer},
title = {{Random forests}},
url = {http://www.springerlink.com/index/U0P06167N6173512.pdf},
volume = {45},
year = {2001}
}
@inproceedings{hackenberg2011lightweight,
author = {Hackenberg, G. and McCall, R. and Broll, W.},
booktitle = {Virtual Reality Conference (VR)},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hackenberg, McCall, Broll - 2011 - Lightweight palm and finger tracking for real-time 3D gesture control.pdf:pdf},
pages = {19--26},
publisher = {IEEE},
title = {{Lightweight palm and finger tracking for real-time 3D gesture control}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5759431},
year = {2011}
}
@inproceedings{ozuysal2007fast,
author = {Ozuysal, M. and Fua, P. and Lepetit, V.},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozuysal, Fua, Lepetit - 2007 - Fast keypoint recognition in ten lines of code.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Fast keypoint recognition in ten lines of code}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/CVPR.2007.383123},
year = {2007}
}
@article{özuysal2010fast,
author = {\"{O}zuysal, M. and Calonder, M. and Lepetit, V. and Fua, P.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/\"{O}zuysal et al. - 2010 - Fast keypoint recognition using random ferns.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {448--461},
publisher = {IEEE Computer Society},
title = {{Fast keypoint recognition using random ferns}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2009.23},
year = {2010}
}
@inproceedings{Fanellia,
author = {Fanelli, Gabriele and Gall, Juergen and {Van Gool}, L.},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fanelli, Gall - Unknown - Real Time Head Pose Estimation with Random Regression Forests.pdf:pdf},
title = {{Real time head pose estimation with random regression forests}},
url = {http://www.vision.ee.ethz.ch/~gfanelli/pubs/cvpr11.pdf},
year = {2011}
}
@article{Uebersax2011,
author = {Uebersax, D and Gall, J},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Uebersax, Gall - 2011 - Real-time Sign Language Letter and Word Recognition from Depth Data.pdf:pdf;:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Uebersax, Gall - 2011 - Real-time Sign Language Letter and Word Recognition from Depth Data(2).pdf:pdf},
journal = {vision.ee.ethz.ch},
title = {{Real-time Sign Language Letter and Word Recognition from Depth Data}},
url = {http://www.vision.ee.ethz.ch/~gallju/download/jgall\_ASL\_hci11.pdf},
year = {2011}
}
@article{Cerveri2007,
abstract = {This paper describes methods and experimental studies concerned with quantitative reconstruction of finger movements in real-time, by means of multi-camera system and 24 surface markers. The approach utilizes a kinematic model of the articulated hand which consists in a hierarchical chain of rigid body segments characterized by 22 functional degrees of freedom and the global roto-translation. This work is focused on the experimental evaluation of a kinematical hand model for biomechanical analysis purposes. From a static posture, a completely automatic calibration procedure, based on anthropometric measures and geometric constraints, computes axes, and centers of rotations which are then utilized as the base of an interactive real-time animation of the hand model. The motion tracking, based on automatic marker labeling and predictive filter, is empowered by introducing constraints from functional finger postures. The validation is performed on four normal subjects through different right-handed motor tasks involving voluntary flexion-extension of the thumb, voluntary abduction-adduction of the thumb, grasping, and finger pointing. Performances are tested in terms of repeatability of angular profiles, model-based ability to predict marker trajectories and tracking success during real-time motion estimation. Results show intra-subject repeatability of the model calibration both to different postures and to re-marking in the range of 0.5 and 2 mm, respectively. Kinematic estimation proves satisfactory in terms of prediction capability (index finger: maximum RMSE 2.02 mm; thumb: maximum RMSE 3.25 mm) and motion reproducibility (R (2) coefficients-index finger: 0.96, thumb: 0.94). During fast grasping sequence (60 Hz), the percentage of residual marker occlusions is less than 1\% and processing and visualization frequency of 50 Hz confirms the real-time capability of the motion estimation system.},
author = {Cerveri, P and {De Momi}, E and Lopomo, N and Baud-Bovy, G and Barros, R M L and Ferrigno, G},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerveri et al. - 2007 - Finger kinematic modeling and real-time hand motion estimation.pdf:pdf},
institution = {Bioengineering Department, Politecnico di Milano University, Piazza Leonardo da Vinci 32, I-20133, Milan, Italy. pietro.cerveri@polimi.it},
journal = {Annals of Biomedical Engineering},
number = {11},
pages = {1989--2002},
pmid = {17701355},
title = {{Finger kinematic modeling and real-time hand motion estimation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17701355},
volume = {35},
year = {2007}
}
@inproceedings{Ren2011,
author = {Ren, Z},
booktitle = {ACM International Conference on Multimedia},
title = {{Robust Hand Gesture Recognition Based on Finger-Earth Mover's Distance with a Commodity Depth Camera}},
url = {http://www.ntu.edu.sg/home/renzhou/Ren\_Yuan\_Zhang\_MM11short.pdf http://www.ntu.edu.sg/home/renzhou/HandGesture.htm},
year = {2011}
}
@article{lepetit2006keypoint,
author = {Lepetit, V. and Fua, P.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lepetit, Fua - 2006 - Keypoint recognition using randomized trees.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {1465--1479},
publisher = {Published by the IEEE Computer Society},
title = {{Keypoint recognition using randomized trees}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TPAMI.2006.188},
year = {2006}
}
@article{Chu2008,
author = {Chu, C W and Nevatia, R},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Nevatia - 2008 - Real-Time 3D Body Pose Tracking from Multiple 2D Images.pdf:pdf},
journal = {Lecture Notes in Computer Science},
pages = {42--52},
publisher = {Springer},
title = {{Real-Time 3D Body Pose Tracking from Multiple 2D Images}},
url = {http://www.springerlink.com/index/j0h67671g36547l7.pdf},
volume = {5098},
year = {2008}
}
@article{tangrecognizing,
abstract = {In this paper, we propose and implement a novel method for recognizing hand gestures using rgb and depth data from Microsoft’s Kinect sensor. Our approach involves looking at specific hand motions, in addition to full body motions, to assist in the recognition of more refined gestures. With this approach, we are able to recognize ‘grasp’ and ‘drop’ gestures with over 90\% accuracy.},
author = {Tang, M.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang - 2011 - Recognizing Hand Gestures with Microsoft’s Kinect.pdf:pdf},
journal = {stanford.edu},
title = {{Recognizing Hand Gestures with Microsoft’s Kinect}},
url = {http://www.stanford.edu/class/ee368/Project\_11/Reports/Tang\_Hand\_Gesture\_Recognition.pdf},
year = {2011}
}
@article{Bo2011,
author = {Bo, L},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bo - 2011 - Depth Kernel Descriptors for Object Recognition.pdf:pdf},
journal = {cs.washington.edu},
title = {{Depth Kernel Descriptors for Object Recognition}},
url = {http://www.cs.washington.edu/homes/xren/publication/bo-iros11-depth-kernel-descriptors.pdf},
year = {2011}
}
@inproceedings{Harrison2011,
abstract = {OmniTouch is a wearable depth-sensing and projection sys- tem that enables interactive multitouch applications on eve- ryday surfaces. Beyond the shoulder-worn system, there is no instrumentation of the user or environment. Foremost, the system allows the wearer to use their hands, arms and legs as graphical, interactive surfaces. Users can also transiently appropriate surfaces from the environment to expand the interactive area (e.g., books, walls, tables). On such surfaces - without any calibration - OmniTouch provides capabilities similar to that of a mouse or touchscreen: X and Y location in 2D interfaces and whether fingers are “clicked” or hovering, enabling a wide variety of interactions. Reliable operation on the hands, for example, requires buttons to be 2.3cm in diameter. Thus, it is now conceivable that anything one can do on today’s mobile devices, they could do in the palm of their hand.},
author = {Harrison, C. and Benko, H. and Wilson, A. D.},
booktitle = {ACM Symposium on User Interface Software and Technology},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Harrison, Benko, Wilson - 2011 - OmniTouch Wearable Multitouch Interaction Everywhere.pdf:pdf},
title = {{OmniTouch: Wearable Multitouch Interaction Everywhere}},
url = {http://www.chrisharrison.net/index.php/Research/OmniTouch},
year = {2011}
}
@article{Shotton2011,
abstract = {We propose a new method to quickly and accurately pre- dict 3D positions of body joints from a single depth image, using no temporal information. We take an object recog- nition approach, designing an intermediate body parts rep- resentation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes. The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of sev- eral training parameters. We achieve state of the art accu- racy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.},
author = {Shotton, Jamie and Sharp, Toby},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shotton, Sharp - 2011 - Real-Time Human Pose Recognition in Parts from Single Depth Images.pdf:pdf},
journal = {Training},
title = {{Real-Time Human Pose Recognition in Parts from Single Depth Images}},
url = {http://research.microsoft.com/pubs/145347/BodyPartRecognition.pdf http://research.microsoft.com/apps/pubs/default.aspx?id=145347},
volume = {2},
year = {2011}
}
@article{Munib2007,
author = {Munib, Q and Habeeb, M and Takruri, B and Almalik, H},
doi = {10.1016/j.eswa.2005.11.018},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Munib et al. - 2007 - American sign language (ASL) recognition based on Hough transform and neural networks.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {american sign language,canny edge detection,feature extraction,hough transform,neural network,sobel edge detection},
month = jan,
number = {1},
pages = {24--37},
title = {{American sign language (ASL) recognition based on Hough transform and neural networks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417405003040},
volume = {32},
year = {2007}
}
@inproceedings{LaViola2011,
address = {New York, New York, USA},
author = {LaViola, Joseph J. and Keefe, Daniel F.},
booktitle = {SIGGRAPH Courses},
doi = {10.1145/2037636.2037637},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/LaViola, Keefe - 2011 - 3D spatial interaction applications for art, design, and science.pdf:pdf},
isbn = {9781450309677},
month = aug,
pages = {1--75},
publisher = {ACM Press},
title = {{3D spatial interaction: applications for art, design, and science}},
url = {http://dl.acm.org/citation.cfm?id=2037636.2037637 http://dl.acm.org/citation.cfm?id=2037637},
year = {2011}
}
@inproceedings{Takimoto2010,
author = {Takimoto, Hironori and Yoshimori, Seiki and Mitsukura, Yasue and Fukumi, Minoru},
booktitle = {RO-MAN, 2010 IEEE},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Takimoto et al. - 2010 - Classification of Hand Postures Based on 3D Vision Model for Human-Robot Interaction.pdf:pdf},
isbn = {9781424479900},
keywords = {Creating Human-Robot Relationships,Detecting and Understanding Human Activity},
pages = {292--297},
publisher = {IEEE},
title = {{Classification of hand postures based on 3D vision model for human-robot interaction}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5598646},
year = {2010}
}
@article{ly2011pose,
annote = {30 minutes per image of 39 DOF quadroped robot!},
archivePrefix = {arXiv},
arxivId = {1106.5341v1},
author = {Ly, D.L. and Saxena, A. and Lipson, H.},
eprint = {1106.5341v1},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ly, Saxena, Lipson - 2011 - Pose estimation from a single depth image for arbitrary kinematic skeletons.pdf:pdf},
journal = {Arxiv preprint},
title = {{Pose estimation from a single depth image for arbitrary kinematic skeletons}},
url = {http://arxiv.org/abs/1106.5341},
year = {2011}
}
@article{Jiang2009,
author = {Jiang, Feng and Gao, Wen and Yao, Hongxun and Zhao, Debin and Chen, Xilin},
doi = {10.1016/j.patrec.2008.12.007},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2009 - Synthetic data generation technique in Signer-independent sign language recognition.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {signer-independent sign recognition,synthetic data driving},
month = apr,
number = {5},
pages = {513--524},
publisher = {Elsevier B.V.},
title = {{Synthetic data generation technique in Signer-independent sign language recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865508003681},
volume = {30},
year = {2009}
}
@inproceedings{Wang2011,
author = {Wang, R. and Paris, Sylvain and Popovi\'{c}, J.},
booktitle = {ACM symposium on User interface software and technology},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Paris, Popovi\'{c} - 2011 - 6D hands markerless hand-tracking for computer aided design.pdf:pdf},
isbn = {9781450307161},
keywords = {3d assembly task controlled,figure 1,for 3d assembly in,hand-tracking sys-,tem using two webcams,the context,we propose a markerless,with hand-tracking},
pages = {549--558},
publisher = {ACM},
title = {{6D hands: markerless hand-tracking for computer aided design}},
url = {http://dl.acm.org/citation.cfm?id=2047269},
year = {2011}
}
@article{Kelly2010,
author = {Kelly, Daniel and McDonald, John and Markham, Charles},
doi = {10.1016/j.patrec.2010.02.004},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly, McDonald, Markham - 2010 - A person independent system for recognition of hand postures used in sign language.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {feature representation},
month = aug,
number = {11},
pages = {1359--1368},
publisher = {Elsevier B.V.},
title = {{A person independent system for recognition of hand postures used in sign language}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000619},
volume = {31},
year = {2010}
}
@article{Fanelli,
author = {Fanelli, Gabriele and Weise, Thibaut and Gall, Juergen and {Van Gool}, L.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fanelli et al. - Unknown - Real Time Head Pose Estimation from Consumer Depth Cameras.pdf:pdf},
journal = {vision.ee.ethz.ch},
title = {{Real Time Head Pose Estimation from Consumer Depth Cameras}},
url = {http://www.vision.ee.ethz.ch/~gfanelli/pubs/dagm11.pdf},
year = {2011}
}
@inproceedings{Oikonomidis2011,
abstract = {We present a novel solution to the problem of recovering and tracking the 3D position, orientation and full articulation of a human hand from markerless visual observations obtained by a Kinect sensor. We treat this as an optimization problem, seeking for the hand model parameters that minimize the discrepancy between the appearance and 3D structure of hypothesized instances of a hand model and actual hand observations. This optimization problem is effectively solved using a variant of Particle Swarm Optimization (PSO). The proposed method does not require special markers and/or a complex image acquisition setup. Being model based, it provides continuous solutions to the problem of tracking hand articulations. Extensive experiments with a prototype GPU-based implementation of the proposed method demonstrate that accurate and robust 3D tracking of hand articulations can be achieved in near real-time (15Hz).},
address = {Dundee, UK},
author = {Oikonomidis, I},
booktitle = {British Machine Vision Conference},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oikonomidis - 2011 - Efficient model-based 3d tracking of hand articulations using kinect.pdf:pdf},
publisher = {University of Dundee},
title = {{Efficient model-based 3d tracking of hand articulations using kinect}},
url = {http://www.ics.forth.gr/~argyros/mypapers/2011\_09\_bmvc\_kinect\_hand\_tracking.pdf},
year = {2011}
}
@inproceedings{lepetit2005randomized,
author = {Lepetit, V. and Lagger, P. and Fua, P.},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lepetit, Lagger, Fua - 2005 - Randomized trees for real-time keypoint recognition.pdf:pdf},
pages = {775--781},
publisher = {IEEE},
title = {{Randomized trees for real-time keypoint recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1467521},
volume = {2},
year = {2005}
}
@inproceedings{shotton2008semantic,
author = {Shotton, J. and Johnson, M. and Cipolla, R.},
booktitle = {Computer Vision and Pattern Recognition},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shotton, Johnson, Cipolla - 2008 - Semantic texton forests for image categorization and segmentation.pdf:pdf},
pages = {1--8},
publisher = {IEEE},
title = {{Semantic texton forests for image categorization and segmentation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4587503},
year = {2008}
}
@article{moosmann2007fast,
author = {Moosmann, F. and Triggs, B. and Jurie, F.},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moosmann, Triggs, Jurie - 2006 - Randomized clustering forests for building fast and discriminative visual vocabularies.pdf:pdf},
journal = {Advances in neural information processing systems},
pages = {985},
publisher = {Citeseer},
title = {{Fast discriminative visual codebooks using randomized clustering forests}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.4267\&amp;rep=rep1\&amp;type=pdf},
volume = {19},
year = {2007}
}
@inproceedings{Lamberti2011,
abstract = {We present a novel method that, given a sequence of syn- chronized views of a human hand, recovers its 3D position, orientation and full articulation parameters. The adopted hand model is based on properly selected and assembled 3D geometric primitives. Hypothesized configurations/poses of the hand model are projected to different cam- era views and image features such as edge maps and hand silhouettes are computed. An objective function is then used to quantify the discrepancy between the predicted and the actual, observed features. The recovery of the 3D hand pose amounts to estimating the parameters that minimize this objective function which is performed using Particle Swarm Opti- mization. All the basic components of the method (feature extraction, objective function evaluation, optimization process) are inherently paral- lel. Thus, a GPU-based implementation achieves a speedup of two orders of magnitude over the case of CPU processing. Extensive experimental results demonstrate qualitatively and quantitatively that accurate 3D pose recovery of a hand can be achieved robustly at a rate that greatly outperforms the current state of the art.},
author = {Lamberti, Luigi and Camastra, Francesco},
booktitle = {International Conference on Image Analysis and Processing (ICIAP)},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamberti, Camastra - 2011 - Real-time hand gesture recognition using a color glove.pdf:pdf},
isbn = {978-3-642-24084-3},
month = sep,
pages = {365--373},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{Real-time hand gesture recognition using a color glove}},
url = {http://dl.acm.org/citation.cfm?id=2042620.2042666},
year = {2011}
}
@article{Forutanpour2011,
author = {Forutanpour, Babak and Ren, Jianfeng},
isbn = {978-3-642-21615-2},
keywords = {camera-projector space,collaborative workspaces,marker-less hand gesture recognition},
month = jul,
pages = {48--58},
title = {{ProJest: enabling higher levels of collaboration using today's mobile devices}},
url = {http://dl.acm.org/citation.cfm?id=2027296.2027303},
year = {2011}
}
@inproceedings{Mo2006,
abstract = {Gesture recognition methods based on intensity or color images often suffer from low efficiency and lack of robustness. In this paper, we employ a new laser-based camera that produces reliable low-resolution depth images at video rates. By decomposing and recognizing hand poses as finger states (finger poses and finger inter-relations), we achieve robust hand pose recognition in real-time (30 frames/second).},
author = {Mo, Zhenyao and Neumann, Ulrich},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2006.237},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mo, Neumann - 2006 - Real-time Hand Pose Recognition Using Low-Resolution Depth Images.pdf:pdf},
isbn = {0769525970},
pages = {1499--1505},
publisher = {Ieee},
title = {{Real-time Hand Pose Recognition Using Low-Resolution Depth Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640934},
volume = {2},
year = {2006}
}
@incollection{Cooper2011,
author = {Cooper, H},
booktitle = {Visual Analysis of Humans},
title = {{Sign Language Recognition}},
url = {http://www.springerlink.com/index/W888384391177535.pdf},
year = {2011}
}
@article{Stergiopoulou2009,
author = {Stergiopoulou, E. and Papamarkos, N.},
doi = {10.1016/j.engappai.2009.03.008},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stergiopoulou, Papamarkos - 2009 - Hand gesture recognition using a neural network shape fitting technique.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Hand gesture,Human–machine interaction,Neural network,Skin color detection,YCbCr color space,human,machine interaction},
month = dec,
number = {8},
pages = {1141--1158},
publisher = {Elsevier},
title = {{Hand gesture recognition using a neural network shape fitting technique}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0952197609000694},
volume = {22},
year = {2009}
}
@inproceedings{Wang2009,
address = {New York, New York, USA},
author = {Wang, Robert Y. and Popovi\'{c}, Jovan},
booktitle = {SIGGRAPH Papers},
doi = {10.1145/1576246.1531369},
file = {:C$\backslash$:/Users/walto011/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Popovi\'{c} - 2009 - Real-time hand-tracking with a color glove.pdf:pdf},
isbn = {9781605587264},
issn = {0730-0301},
keywords = {augmented reality,hand tracking,motion capture,user interface},
month = jul,
number = {3},
pages = {1},
publisher = {ACM Press},
title = {{Real-time hand-tracking with a color glove}},
url = {http://dl.acm.org/citation.cfm?id=1576246.1531369},
volume = {28},
year = {2009}
}
